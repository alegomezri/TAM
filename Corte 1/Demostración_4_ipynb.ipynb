{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Consideremos la función de log-verosimilitud de una muestra $( x )$ proveniente de una distribución normal con media $( \\mu $) y varianza $( \\sigma^2 )$:\n",
        "\n",
        "\n",
        "$$\\log(\\rho(x)) = -\\frac{N}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{n=1}^{N} (x_n - \\mu)^2$$\n",
        "\n",
        "Tomando la derivada parcial de la función de log-verosimilitud con respecto a $( \\sigma^2 )$ y buscando el punto donde esta derivada es cero:\n",
        "\n",
        "$$\\frac{\\partial}{\\partial \\sigma^2} \\left( -\\frac{N}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{n=1}^{N} (x_n - \\mu)^2 \\right) = 0\n",
        "$$\n",
        "\n",
        "\n",
        "La derivada es:\n",
        "$$-\\frac{N}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{n=1}^{N} (x_n - \\mu)^2 = 0\n",
        "$$\n",
        "\n",
        "Multiplicando por $( -2(\\sigma^2)^2 $) y reorganizando los términos, encontramos la estimación de máxima verosimilitud para $(\\sigma^2)$:\n",
        "$$\\sigma^2 = \\frac{1}{N} \\sum_{n=1}^{N} (x_n - \\mu)^2\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "KUT4bqzGlC_o"
      }
    }
  ]
}